{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1TVGjfHsVV2A8Hv7YQ7Or4hL8QeM6L_Bb",
      "authorship_tag": "ABX9TyOLpUFis039bS9o+4CO96Mj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Theophilus12/Machine-Learning-Accuracy-For-Income-Classification/blob/main/Adult.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3cmUdHncEDI"
      },
      "source": [
        "# importing of libraries \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIunEpqoc5Se",
        "outputId": "2b286f9f-dd0e-44b2-c5ad-b377e87d9c93"
      },
      "source": [
        "#Google Drive Launching \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQyRUkNtd5YT"
      },
      "source": [
        "# reading the dataset\n",
        "adult_df=pd.read_csv('/content/drive/MyDrive/adult.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_bpsiW6fEVn",
        "outputId": "bea8a3a2-6e42-4279-a366-7eafec9cdf30"
      },
      "source": [
        "#data size\n",
        "adult_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32561, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfqhPus9L-XK",
        "outputId": "3c75ffc6-1df4-41f8-938b-95e28071c726"
      },
      "source": [
        "#Now let us take a glance at all of the categorical columns that our dataset contains.\n",
        "adult_df.select_dtypes(exclude=np.number).columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['workclass', 'education', 'marital.status', 'occupation',\n",
              "       'relationship', 'race', 'sex', 'native.country', 'income'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDCEJJFJMp8p"
      },
      "source": [
        "#Now let us take a glance at all of our dataset's numerical columns.\n",
        "adult_df.select_dtypes(include= np.number).columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "368aAgs6eTYd"
      },
      "source": [
        "adult_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdEkd-pchzqm"
      },
      "source": [
        "#replacing some special character columns names with proper names \n",
        "adult_df.rename(columns={'capital.gain': 'capital gain', 'fnlwgt': 'final weight','capital.loss': 'capital loss', 'native.country': 'country','hours.per.week': 'hours per week','marital.status': 'marital','sex':'gender'}, inplace=True)\n",
        "adult_df.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J4McAGhfK5j"
      },
      "source": [
        "#analysising information about the dataset \n",
        "adult_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGdzd3QTffAN"
      },
      "source": [
        "adult_df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNnlIs-WlxCH"
      },
      "source": [
        "# checking for null value\n",
        "adult_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31HSvfIwlqiJ"
      },
      "source": [
        "adult_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQbRL75cnYdv"
      },
      "source": [
        "There are no null value in the dataset, i will check for this special (?) character in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWgd_laTno6x"
      },
      "source": [
        "# checking throught the dataset for '?'\n",
        "adult_df.isin(['?']).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eQxqioJpUPc"
      },
      "source": [
        "there are three columns having this special character \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YixiOZakwzyE"
      },
      "source": [
        "replacing '?' to NAN for 'workclass', 'occupation', 'country'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTLG6xmKpah3"
      },
      "source": [
        "# replacing '?' in the workclass column to NAN\n",
        "adult_df['workclass'] =adult_df['workclass'].replace('?', np.NAN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEtyJSTewpsd"
      },
      "source": [
        "adult_df['workclass']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwClAbAuybUP"
      },
      "source": [
        "# replacing '?' in the occupation column to NAN\n",
        "adult_df['occupation'] =adult_df['occupation'].replace('?', np.NAN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmsqVREAymbk"
      },
      "source": [
        "adult_df['occupation']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-OJhf_uyubA"
      },
      "source": [
        "# replacing '?' in country column to NAN\n",
        "adult_df['country']=adult_df['country'].replace('?', np.NAN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HJ82yyky2gG"
      },
      "source": [
        "adult_df['country']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4yb_aBNz_8y"
      },
      "source": [
        "i dont feel like generating dumie variable, i will be dropping all the rows with NAN VALUE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu-WWK_M0MPo"
      },
      "source": [
        "#dropping rows with NAN VALUE\n",
        "adult_df.dropna(axis=0, how='any', thresh=None, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfjpb8U00sl2",
        "outputId": "573fc4d9-12bb-4913-a24f-5c1e08f64ee9"
      },
      "source": [
        "adult_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30162, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWCUJnYa42Vv"
      },
      "source": [
        "adult_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfqV22HgS1P-"
      },
      "source": [
        "adult_df.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf_klVJt3ivV"
      },
      "source": [
        "The describe technique displays the following fundamental statistical properties of each numerical highlight (int64, float64): number of non-missing values,standard deviation, mode, and median."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Lgaj0As3iGr"
      },
      "source": [
        "adult_df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byLplp2SBQEJ"
      },
      "source": [
        "# numerical features of the dataset\n",
        "numerical_features= adult_df.select_dtypes(include= ['float64', 'int64'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2U1nzmpCAuK"
      },
      "source": [
        "numerical_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oA-b5ztCeul"
      },
      "source": [
        "# using histogram to illustrate the numerical features of the dataset and analyse the distribution freqency among the features in the dataset\n",
        "numerical_features.hist(figsize= (20, 20), bins= 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPgFn9ZO7Xh0"
      },
      "source": [
        "Let's glance at some non-numerical/categorical numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvDbEy3P7Y_l"
      },
      "source": [
        "adult_df.describe(include=['object'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-X3xQk2ENd4"
      },
      "source": [
        "#non-numerical/categorical numbers\n",
        "categorical_features = adult_df.select_dtypes('object')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdV0zCdvEgtA"
      },
      "source": [
        "categorical_features.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woRZEn1s7eFl"
      },
      "source": [
        "adult_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh9crRsQ-9i9"
      },
      "source": [
        "#Changing the income columns to Int Data type \n",
        "adult_df['income'].replace({'<=50K':0,'>50K':1},inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2iEckDGeMfV"
      },
      "source": [
        "Grouping the Country into either USA or NON USA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwIbPSpXWLrQ"
      },
      "source": [
        "# grouping the column country into united state and non_usa\n",
        "adult_df.loc[adult_df['country']!='United-States','country'] = 'non_usa'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5utUnOWXZgy"
      },
      "source": [
        "# checking the collobration of each  columns with income\n",
        "import seaborn as sns\n",
        "fig, ((a,b),(c,d),(e,f),(g,h)) = plt.subplots(4,2,figsize=(25,20))\n",
        "plt.xticks(rotation=45)\n",
        "sns.countplot(adult_df['workclass'],hue=adult_df['income'],ax=f)\n",
        "sns.countplot(adult_df['relationship'],hue=adult_df['income'],ax=b)\n",
        "sns.countplot(adult_df['marital'],hue=adult_df['income'],ax=c)\n",
        "sns.countplot(adult_df['race'],hue=adult_df['income'],ax=d)\n",
        "sns.countplot(adult_df['gender'],hue=adult_df['income'],ax=e)\n",
        "sns.countplot(adult_df['country'],hue=adult_df['income'],ax=a)\n",
        "sns.countplot(adult_df['education.num'],hue=adult_df['income'],ax=g)\n",
        "sns.countplot(adult_df['workclass'],hue=adult_df['income'],ax=h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXKGOJe5Kl17"
      },
      "source": [
        "Figuring the relationship between the dependent variable and all other variables. For the same, I'll make a heatmap. Examine the last row, which represents 'income,' for a correlation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKWV1re67zmx"
      },
      "source": [
        "# corrolation matrix between income and numerical features\n",
        "plt.figure(figsize=(15,15))\n",
        "corrolation_matrix=adult_df.corr()\n",
        "sns.heatmap(corrolation_matrix, annot=True, cbar=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRO6j9NyOmOq"
      },
      "source": [
        "The correlation is between -1 and +1. All of the diagonal components in a correlation heatmap will be 1, indicating high correlation since they all overlap."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSgOod1xtndv"
      },
      "source": [
        "# sorting dependent variable and all other variables\n",
        "corrolation_matrix['income'].sort_values(ascending = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAZF6CekOMgC"
      },
      "source": [
        "#Finding what percentage of data is missing from the dataset\n",
        "total = adult_df.isnull().sum().sort_values(ascending=False)\n",
        "percent_1 = adult_df.isnull().sum()/adult_df.isnull().count()*100\n",
        "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
        "missing_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxgzKNEXOV_9"
      },
      "source": [
        "#checking for income percentage in the dataset\n",
        "adult_df['income'].value_counts(normalize=True)*100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiXpT5OfOcX6"
      },
      "source": [
        "# checking for the analysis income\n",
        "sns.countplot(adult_df['income'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BqxrF19OnHJ"
      },
      "source": [
        "There is an unequal distribution of wealth. 75% percent of the analyses make less than or equivalent to $50,000."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-0ukYhRiQQW"
      },
      "source": [
        "To make an accurate prediction, we must first comprehend the details. Let's go through each function, analyze it, and see how it relates to the income parameter \"income.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJIstQt6h2ZV"
      },
      "source": [
        "# age and income\n",
        "pd.crosstab(adult_df.age,adult_df.income).plot(kind='bar', figsize=(20,10), stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIewNit2HY2i"
      },
      "source": [
        "# the statistical interpretation age and income \n",
        "adult_df.groupby('age').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_qI3yw1qcHH"
      },
      "source": [
        "1. from the graph teenagers within the Age 17-20 cant earn 50k based on UK POLICY   \n",
        "2.from 21 above, there are high tendency to earn $50k above "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg8bf7jNh2VU"
      },
      "source": [
        "# education level determines the income \n",
        "pd.crosstab(adult_df.education,adult_df.income).plot(kind='bar', figsize=(20,10), stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7KbQrLevQuq"
      },
      "source": [
        "#the statistical interpretation  education and income\n",
        "adult_df.groupby('education').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Gx9kAr1wJ5w"
      },
      "source": [
        "1. High school Graduate can harly earn 50k\n",
        "2. To earn 50k above a minimum of Bachelor degree is needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CltewbhAwI-Y"
      },
      "source": [
        "# hours per week and Income\n",
        "pd.crosstab(adult_df['hours per week'],adult_df.income).plot(kind='bar', figsize=(20,5), stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVV-ZGpKGqcp"
      },
      "source": [
        "# the statistical interpretation hours per week and income\n",
        "adult_df.groupby('hours per week').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4p96yTyW5wqD"
      },
      "source": [
        "people are working 40 hours per week, people who work more than 40 hours a week can earn more"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfrinmyneIw7"
      },
      "source": [
        "# income and occupation\n",
        "pd.crosstab(adult_df.occupation,adult_df.income).plot(kind='bar', figsize=(20,10), stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjLCUXLMh4YP"
      },
      "source": [
        "# the statistical interpretation occupation and income\n",
        "adult_df.groupby('occupation').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHcjCf4egFJP"
      },
      "source": [
        "# income and race\n",
        "pd.crosstab(adult_df.race,adult_df.income).plot(kind='bar', figsize=(20,10), stacked=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSWCV34XfWL_"
      },
      "source": [
        "people who work as an excutive management and with professional skills has the tendency to earn 50k"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovO6W7XZiFUl"
      },
      "source": [
        "# the statistical interpretation race and income\n",
        "adult_df.groupby('race').income.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7x_fUMcKhHil"
      },
      "source": [
        "white has High tendency to earn 50k compared to others ethnic groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "801UTpyM4ZbG"
      },
      "source": [
        "Label Enconding: \n",
        "Enconding the Categorical Variable from Object to Integer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GiYoX2iLzccc"
      },
      "source": [
        "# encoding categorical variables\n",
        "# LABELLED Encoder is used to translate the object type to Int.\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "for feature in categorical_features:\n",
        "        le = preprocessing.LabelEncoder()\n",
        "        adult_df[feature] = le.fit_transform(adult_df[feature])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wh0OJgXVz_6p"
      },
      "source": [
        "adult_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzYVvEXJ7LbA"
      },
      "source": [
        "Split the Dataset Into Training and Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32Bbw0QS7VIz"
      },
      "source": [
        "#Splitting the data into test data and training data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = adult_df.iloc[:,0:14]\n",
        "Y = adult_df.iloc[:,14]\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JKKjM09Af-y"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn3suSe6HVXJ"
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpOIJ_diAm7h"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAeBVoNBHbAp"
      },
      "source": [
        "Y_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW6LhgZAKeyA"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCr52taPKiUc"
      },
      "source": [
        "# Create an instance of Logistic Regression Classifier and fit the data.\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6JyIEFZXEfz"
      },
      "source": [
        "#testing of the entire dataset\n",
        "prediction=logreg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LIYL_TlXh_U"
      },
      "source": [
        "#getting the %accuracy of the Logistics Regression\n",
        "from sklearn.metrics import accuracy_score\n",
        "log_acccuracy=logreg.score(X_test,Y_test)\n",
        "log_acccuracy *100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti4RKKe39_jL"
      },
      "source": [
        "# generating the classification report for logistics_regression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(Y_test, prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVwgDI0Evvlg"
      },
      "source": [
        "# predict probabilities\n",
        "logreg_probs = logreg.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "logreg_probs = logreg_probs[:, 1]\n",
        "ns_probs = [0 for _ in range(len(Y_test))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUFmR-tJwkj4"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# calculate scores\n",
        "nsreg_auc = roc_auc_score(Y_test, ns_probs)\n",
        "logreg_auc = roc_auc_score(Y_test, logreg_probs)\n",
        "# summarize scores\n",
        "print('Random Prediction: ROC AUC=%.3f' % (nsreg_auc))\n",
        "print('Logistic: ROC AUC=%.3f' % (logreg_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQABSHL93Rwx"
      },
      "source": [
        "#generate the confusion matrix for logistic_regression \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "cmtlog = confusion_matrix(Y_test, prediction)\n",
        "fig, (ax) = plt.subplots(1, 1, figsize=(10,7))\n",
        "sns.heatmap(cmtlog, annot=True, ax = ax,fmt='g')\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix Logistics Regression')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awk4SW9mh73c"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8q1XFk4jDJa"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import tree\n",
        "#function to perform training with Entropy\n",
        "df_entropy= DecisionTreeClassifier(criterion='entropy', random_state=100, max_depth=3, min_samples_leaf=15)\n",
        "df_entropy.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifgMOVQPnABV"
      },
      "source": [
        "# function to make prediction\n",
        "tree_prediction=df_entropy.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdfUAoWBoPwG"
      },
      "source": [
        "#getting the %accuracy of the Decision Tree\n",
        "tree_acccuracy =df_entropy.score(X_test,Y_test)\n",
        "tree_acccuracy *100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldqS-EQHWCHx"
      },
      "source": [
        "#generating the classification report for DecisionTree\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(Y_test, tree_prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5qoHTWB1imP"
      },
      "source": [
        "# predict probabilities\n",
        "dtree_probs = df_entropy.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "dtree_probs = dtree_probs[:, 1]\n",
        "nstree_probs = [0 for _ in range(len(Y_test))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlqHTA-X2cj-"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# calculate scores\n",
        "nstree_auc = roc_auc_score(Y_test, nstree_probs)\n",
        "dtree_auc = roc_auc_score(Y_test, dtree_probs)\n",
        "# summarize scores\n",
        "print('Random Prediction: ROC AUC=%.3f' % (nstree_auc))\n",
        "print('Decision Tree: ROC AUC=%.3f' % (dtree_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQ3ILALu_PK9"
      },
      "source": [
        " #generate the confusion matrix for Decision Tree\n",
        "cmtree = confusion_matrix(Y_test, tree_prediction)\n",
        "fig, (ax) = plt.subplots(1, 1, figsize=(8,7))\n",
        "sns.heatmap(cmtree, annot=True, ax = ax,fmt='g')\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix Decision Tree')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkDskCk-vl7g"
      },
      "source": [
        "from IPython.display import Image  \n",
        "from six import StringIO \n",
        "import pydotplus\n",
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "dot_data = StringIO()  \n",
        "dt = DecisionTreeClassifier(max_depth=6, max_leaf_nodes=12)\n",
        "\n",
        " \n",
        "\n",
        "# fit model\n",
        "dt.fit(X_train, Y_train)\n",
        "export_graphviz(dt, out_file=dot_data, class_names=[\"No\", \"Yes\"], feature_names=X_train.columns, impurity=False, filled=True)  \n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "Image(graph.create_png())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCVN5OvPrxfI"
      },
      "source": [
        "Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_CrJ4k4daCX"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rforest=RandomForestClassifier(n_jobs=2, n_estimators=100, random_state=0)\n",
        "rforest.fit(X_train,Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH5WalZed08z"
      },
      "source": [
        "# predicting the Test set\n",
        "rforest_prediction= rforest.predict(X_test)\n",
        "rforest_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml5EmjgTePlS"
      },
      "source": [
        "Rforest_acccuracy =rforest.score(X_test,Y_test)\n",
        "Rforest_acccuracy *100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azz1ehDvfEzA"
      },
      "source": [
        "# generating the classification report for Random Forest\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(classification_report(Y_test, rforest_prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2XmWCfi9GB6"
      },
      "source": [
        "# predict probabilities\n",
        "forest_probs = rforest.predict_proba(X_test)\n",
        "# keep probabilities for the positive outcome only\n",
        "forest_probs = forest_probs[:, 1]\n",
        "rforestns_probs = [0 for _ in range(len(Y_test))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY-_BLdM-Xzy"
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# calculate scores\n",
        "nsforest_auc = roc_auc_score(Y_test, forest_probs)\n",
        "rforest_auc = roc_auc_score(Y_test, rforestns_probs)\n",
        "# summarize scores\n",
        "print('Random Prediction: ROC AUC=%.3f' % (rforest_auc))\n",
        "print('Random Forest: ROC AUC=%.3f' % (nsforest_auc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi87bH08fTX6"
      },
      "source": [
        "#generate the confusion matrix for Random Forest\n",
        "cmrforest = confusion_matrix(Y_test, rforest_prediction)\n",
        "fig, (ax) = plt.subplots(1, 1, figsize=(8,7))\n",
        "sns.heatmap(cmrforest, annot=True, ax = ax,fmt='g')\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels');\n",
        "ax.set_title('Confusion Matrix Random Forest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAfBnFZp0eu2"
      },
      "source": [
        "classifiers = [rforest, logreg,df_entropy]\n",
        "\n",
        "# Establish a DataFrame from a data sheet.\n",
        "income_result = pd.DataFrame(columns=['classifiers', 'fpr','tpr','auc'])\n",
        "\n",
        " \n",
        "\n",
        "# Train the models and record the results\n",
        "for clas in classifiers:\n",
        "    dclass = clas.predict_proba(X_test)[::,1]\n",
        "    \n",
        "    fpr, tpr, _ = roc_curve(Y_test,  dclass)\n",
        "    auc = roc_auc_score(Y_test, dclass)\n",
        "    \n",
        "    income_result = income_result.append({'classifiers':clas.__class__.__name__,\n",
        "                                        'fpr':fpr, \n",
        "                                        'tpr':tpr, \n",
        "                                        'auc':auc}, ignore_index=True)\n",
        "\n",
        " \n",
        "\n",
        "# Set name of the classifiers as index labels\n",
        "income_result.set_index('classifiers', inplace=True)\n",
        "income_result.sort_values('auc',ascending=False,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCjK_NR_zb12"
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\n",
        "\n",
        "for j in income_result.index:\n",
        "    plt.plot(income_result.loc[j]['fpr'], \n",
        "             income_result.loc[j]['tpr'], \n",
        "             label=\"{}, AUC={:.3f}\".format(j, income_result.loc[j]['auc']))\n",
        "    \n",
        "plt.plot([0,1], [0,1], color='red')\n",
        "\n",
        " \n",
        "\n",
        "plt.xticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.xlabel(\"False Positive\", fontsize=10)\n",
        "\n",
        " \n",
        "\n",
        "plt.yticks(np.arange(0.0, 1.1, step=0.1))\n",
        "plt.ylabel(\"True Positive\", fontsize=10)\n",
        "\n",
        " \n",
        "\n",
        "plt.title('ROC Curve Analysis', fontweight='bold', fontsize=15)\n",
        "plt.legend(prop={'size':10}, loc='lower right')\n",
        "\n",
        " \n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}